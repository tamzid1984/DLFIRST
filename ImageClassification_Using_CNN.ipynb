{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamzid1984/DLFIRST/blob/main/ImageClassification_Using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a44a4522-3d3d-4019-884a-603170f7f44b",
      "metadata": {
        "id": "a44a4522-3d3d-4019-884a-603170f7f44b"
      },
      "outputs": [],
      "source": [
        "#import module\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e4559c2-0f19-4d26-9d47-7e9e730b8e45",
      "metadata": {
        "id": "1e4559c2-0f19-4d26-9d47-7e9e730b8e45"
      },
      "source": [
        "### Initialize The CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feb7811c-74ec-4ebc-bfa5-a5f1964c4236",
      "metadata": {
        "id": "feb7811c-74ec-4ebc-bfa5-a5f1964c4236"
      },
      "outputs": [],
      "source": [
        "classifier = Sequential() # Empty Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06e3cfe5-ebf7-4405-8a72-2d7465899566",
      "metadata": {
        "id": "06e3cfe5-ebf7-4405-8a72-2d7465899566"
      },
      "outputs": [],
      "source": [
        "classifier.add(Conv2D(32, (3, 3), input_shape = (128, 128, 3), activation = \"relu\")) # 1st Hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df117d0d-269d-4897-8d04-91eb24d0967b",
      "metadata": {
        "id": "df117d0d-269d-4897-8d04-91eb24d0967b"
      },
      "outputs": [],
      "source": [
        "classifier.add(MaxPooling2D(pool_size = (2, 2))) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99d3b316-9548-4cd4-bccc-b6e3e76fd4a1",
      "metadata": {
        "id": "99d3b316-9548-4cd4-bccc-b6e3e76fd4a1"
      },
      "outputs": [],
      "source": [
        "classifier.add(Conv2D(64, (3, 3), activation = \"relu\"))# 2nd Hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c2a84a1-0f88-4bb9-8945-2ffc93983c2f",
      "metadata": {
        "id": "1c2a84a1-0f88-4bb9-8945-2ffc93983c2f"
      },
      "outputs": [],
      "source": [
        "classifier.add(MaxPooling2D(pool_size = (2, 2))) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d17472c2-6ff8-46c4-b009-46a161e278d5",
      "metadata": {
        "id": "d17472c2-6ff8-46c4-b009-46a161e278d5"
      },
      "outputs": [],
      "source": [
        "classifier.add(Conv2D(128, (3, 3), activation = \"relu\"))# 3rd Hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17b5b777-6bc2-4069-9d76-9992fa69732f",
      "metadata": {
        "id": "17b5b777-6bc2-4069-9d76-9992fa69732f"
      },
      "outputs": [],
      "source": [
        "classifier.add(MaxPooling2D(pool_size = (2, 2))) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd2d36d9-f688-41d7-b792-b6ebe8a7e775",
      "metadata": {
        "id": "dd2d36d9-f688-41d7-b792-b6ebe8a7e775"
      },
      "outputs": [],
      "source": [
        "classifier.add(Flatten()) # 1d Array"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19d2a712-5cfd-4283-860c-44bbad1b59cf",
      "metadata": {
        "id": "19d2a712-5cfd-4283-860c-44bbad1b59cf"
      },
      "source": [
        "### Connected Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3ab5e71-2669-41df-bf9e-736d22272dcb",
      "metadata": {
        "id": "a3ab5e71-2669-41df-bf9e-736d22272dcb"
      },
      "outputs": [],
      "source": [
        "classifier.add(Dense(128, activation = 'relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9dff5b1-bbca-44eb-8df6-ca8b950182b2",
      "metadata": {
        "id": "c9dff5b1-bbca-44eb-8df6-ca8b950182b2"
      },
      "outputs": [],
      "source": [
        "classifier.add(Dense(3, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4194c3b6-703b-447a-b7ae-58c0ca311c14",
      "metadata": {
        "id": "4194c3b6-703b-447a-b7ae-58c0ca311c14"
      },
      "outputs": [],
      "source": [
        "classifier.compile(optimizer='adam',\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa6858ff-1e6b-4956-9bb9-c08cc4b68702",
      "metadata": {
        "id": "aa6858ff-1e6b-4956-9bb9-c08cc4b68702"
      },
      "source": [
        "### Fitting Images with the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93fbc669-a1e7-45ab-9c3c-f920fa019fa0",
      "metadata": {
        "id": "93fbc669-a1e7-45ab-9c3c-f920fa019fa0"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, \n",
        "                                  shear_range = 0.2,\n",
        "                                  zoom_range = 0.2, \n",
        "                                  horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23c86fa0-907b-465b-9a6f-cf48c54ffe9c",
      "metadata": {
        "id": "23c86fa0-907b-465b-9a6f-cf48c54ffe9c"
      },
      "outputs": [],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50903259-192a-4030-b6fa-3f8b48c4d11c",
      "metadata": {
        "id": "50903259-192a-4030-b6fa-3f8b48c4d11c",
        "outputId": "d014fb26-c708-4963-c467-4f2b0a51ead0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2400 images belonging to 3 classes.\n",
            "Found 600 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "training_dataset = train_datagen.flow_from_directory(\"dataset/training_set\", target_size = (128, 128), batch_size=32, class_mode = \"categorical\")\n",
        "test_dataset = test_datagen.flow_from_directory(\"dataset/test_set\",target_size = (128, 128), batch_size =32, class_mode = \"categorical\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1e205f5-18e4-4808-94e0-99886fe90fc1",
      "metadata": {
        "id": "e1e205f5-18e4-4808-94e0-99886fe90fc1",
        "outputId": "27d61871-2aa3-415a-aaf4-4e21209ff2c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "25/25 [==============================] - 32s 477ms/step - loss: 1.3176 - accuracy: 0.3244 - val_loss: 1.0938 - val_accuracy: 0.3304\n",
            "Epoch 2/5\n",
            "25/25 [==============================] - 11s 454ms/step - loss: 1.0953 - accuracy: 0.3575 - val_loss: 1.0789 - val_accuracy: 0.4464\n",
            "Epoch 3/5\n",
            "25/25 [==============================] - 17s 672ms/step - loss: 1.0815 - accuracy: 0.4057 - val_loss: 1.0062 - val_accuracy: 0.4777\n",
            "Epoch 4/5\n",
            "25/25 [==============================] - 12s 472ms/step - loss: 1.0411 - accuracy: 0.4603 - val_loss: 1.0188 - val_accuracy: 0.5312\n",
            "Epoch 5/5\n",
            "25/25 [==============================] - 13s 515ms/step - loss: 0.9692 - accuracy: 0.5455 - val_loss: 0.9024 - val_accuracy: 0.5982\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc2a8a51490>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier.fit(training_dataset, steps_per_epoch=800/32, epochs=5, validation_data=test_dataset, validation_steps= 200/32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7777752c-2aca-4504-87bf-cf9f39d67e4c",
      "metadata": {
        "id": "7777752c-2aca-4504-87bf-cf9f39d67e4c"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "target_dirctory = \"dataset/model/\"\n",
        "if not os.path.exists(target_dirctory):\n",
        "    os.mkdir(target_dirctory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc1c5af0-9078-4843-a841-1318b34059d1",
      "metadata": {
        "id": "cc1c5af0-9078-4843-a841-1318b34059d1"
      },
      "outputs": [],
      "source": [
        "classifier.save(\"dataset/model/model.h5\")\n",
        "classifier.save_weights(\"dataset/model/weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6493b326-78fc-4b17-8f2d-4c4db95ce307",
      "metadata": {
        "id": "6493b326-78fc-4b17-8f2d-4c4db95ce307"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.models import Sequential, load_model\n",
        "from PIL import Image, ImageTk\n",
        "from io import BytesIO\n",
        "import requests\n",
        "from tkinter import Tk, Label,Canvas, NW, Entry, Button\n",
        "from keras.preprocessing import image as image_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79bd44bb-d5f2-484a-b79a-58304f5c8ef5",
      "metadata": {
        "id": "79bd44bb-d5f2-484a-b79a-58304f5c8ef5"
      },
      "outputs": [],
      "source": [
        "#Load Model\n",
        "image_width, image_height = 128, 128\n",
        "model_path = \"dataset/model/model.h5\"\n",
        "model_wieght_path = \"dataset/model/weights.h5\"\n",
        "model = load_model(model_path)\n",
        "model.load_weights(model_wieght_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95dbb17f-de9e-4e30-b3bc-fa83b4573487",
      "metadata": {
        "id": "95dbb17f-de9e-4e30-b3bc-fa83b4573487"
      },
      "outputs": [],
      "source": [
        "url = ''\n",
        "window = Tk()\n",
        "window.title(\"Image Classification\")\n",
        "window.geometry(\"800x600\")\n",
        "lbl = Label(window, text = \"Please Enter The Image Url\", font = (\"Halvetica\", 16))\n",
        "lbl.pack()\n",
        "\n",
        "\n",
        "def Enter():\n",
        "    global url\n",
        "    lbl.configure()\n",
        "    url = (User_input.get())\n",
        "    print(url)\n",
        "    \n",
        "    \n",
        "    response = requests.get(url)\n",
        "    test_image = Image.open(BytesIO(response.content))\n",
        "    put_image = test_image.resize((400, 400))\n",
        "    test_image = test_image.resize((128, 128))\n",
        "    \n",
        "    img = ImageTk.PhotoImage(put_image)\n",
        "    pic = Label(image = img)\n",
        "    pic.pack()\n",
        "    pic.image = img\n",
        "    test_image = image_utils.img_to_array(test_image)\n",
        "    test_image = np.expand_dims(test_image, axis = 0)\n",
        "    \n",
        "    result = model.predict_on_batch(test_image)\n",
        "    \n",
        "    \n",
        "    if result[0][0] == 1:\n",
        "        ans = \"French Fries\"\n",
        "    elif result[0][1] == 1:\n",
        "        ans = \"Fizza\"\n",
        "    elif result[0][2] == 1:\n",
        "        ans =  \"samosa\"\n",
        "        \n",
        "    out = Label(window, text = \"Predicted Results: \" + ans, font = (\"Halvetica\", 16))\n",
        "    \n",
        "    out.pack()\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bd80fd1-10ac-42cc-b767-a0cf8820b994",
      "metadata": {
        "id": "1bd80fd1-10ac-42cc-b767-a0cf8820b994",
        "outputId": "582f0538-6682-4d98-9ca9-c43b738d9f04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://www.justataste.com/wp-content/uploads/2020/04/recipe-pizza-dough-without-yeast.jpg\n"
          ]
        }
      ],
      "source": [
        "User_input = Entry(width = 100)\n",
        "User_input.pack()\n",
        "button = Button(window, text = \"Detect the Image\", font = (\"Halvetica\", 16), command = Enter)\n",
        "button.pack()\n",
        "window.mainloop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33b6c78d-8700-4619-ad72-c944c28b7cd2",
      "metadata": {
        "id": "33b6c78d-8700-4619-ad72-c944c28b7cd2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}